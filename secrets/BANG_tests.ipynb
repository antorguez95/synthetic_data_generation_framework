{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import os \n",
    "\n",
    "############################################ ARGUMENTS #####################################\n",
    "\n",
    "# Path where directories are stored\n",
    "DICT_PATH = r\"C:\\Users\\aralmeida\\OneDrive - Universidad de Las Palmas de Gran Canaria\\Doctorado\\codigo\\synthetic_data_generation_framework\\Bangladesh\\results\"\n",
    "\n",
    "dataset_name = 'BANG'\n",
    "\n",
    "# Variables needed to handle dictionaries (same as )\n",
    "# Number of generated data samples \n",
    "sizes_keys = [\"quarter\", \"half\", \"unit\", \"double\", \"quadruple\", \"only-synth\"]\n",
    "\n",
    "# Balancing Methods \n",
    "balance1 = \"ADASYN\"\n",
    "balance2 = \"Borderline\"\n",
    "\n",
    "# Augmentation methods\n",
    "augmen1 = \"CTGAN\"\n",
    "augmen2 = \"GC\"\n",
    "\n",
    "best_worst = ['Borderline + Sep. + GC', 'ADASYN + CTGAN'] \n",
    "\n",
    "models = ['SVM','RF', 'XGB', 'KNN']\n",
    "\n",
    "model_colors = ['b','r','k','g']\n",
    "\n",
    "# Chosen colors for each combinations\n",
    "ctgan_colors = [\"k\",\"r\",\"g\",\"b\"]\n",
    "gc_colors = [\"c\",\"m\",\"y\",\"orange\"]\n",
    "\n",
    "# Studied metrics\n",
    "mets = [\"PCD\",\"MMD\",\"KLD\"]\n",
    "\n",
    "# Strings containing combinations of SDG (Synthetic Data Generators) \n",
    "comb1 = (\"%s + %s\") % (balance1, augmen1)\n",
    "comb2 = (\"%s + %s\") % (balance1, augmen2)\n",
    "comb3 = (\"%s + %s\") % (balance2, augmen1)\n",
    "comb4 = (\"%s + %s\") % (balance2, augmen2)\n",
    "comb5 = (\"%s + Sep. + %s\") % (balance1, augmen1)\n",
    "comb6 = (\"%s + Sep. + %s\") % (balance1, augmen2)\n",
    "comb7 = (\"%s + Sep. + %s\") % (balance2, augmen1)\n",
    "comb8 = (\"%s + Sep. + %s\") % (balance2, augmen2)\n",
    "comb9 = \"%s\" % (augmen1)\n",
    "comb10 = \"Sep. + %s\" % (augmen1)\n",
    "\n",
    "# Split CTGAN and Gaussian Copula methods to plot them separately\n",
    "ctgan_combinations = [comb1, comb3, comb5, comb7]\n",
    "gc_combinations = [comb2, comb4, comb6, comb8]\n",
    "\n",
    "############################################ ARGUMENTS #####################################\n",
    "\n",
    "# Go to that directory\n",
    "os.chdir(DICT_PATH)\n",
    "\n",
    "# Load dictionaries \n",
    "# Synthetic Data metrics \n",
    "sdg_dict = open(\"sdg_metrics.pkl\", \"rb\")\n",
    "sdg_metrics = pickle.load(sdg_dict)\n",
    "\n",
    "# Classification metrics \n",
    "class_metrics_dict = open(\"class_metrics.pkl\", \"rb\")\n",
    "class_metrics = pickle.load(class_metrics_dict)\n",
    "\n",
    "# Hyperparameters \n",
    "hp_dict = open(\"hyperparameters.pkl\", \"rb\")\n",
    "hyperparameters = pickle.load(hp_dict)\n",
    "\n",
    "# Load reference F1 values \n",
    "s = open(\"svm_f1.txt\", \"rb\")\n",
    "SVM_f1_nosynth = pickle.load(s)\n",
    "s = open(\"rf_f1.txt\", \"rb\")\n",
    "rf_f1_nosynth = pickle.load(s)\n",
    "s = open(\"xgb_f1.txt\", \"rb\")\n",
    "xgb_f1_nosynth = pickle.load(s)\n",
    "s = open(\"knn_f1.txt\", \"rb\")\n",
    "knn_f1_nosynth = pickle.load(s)\n",
    "\n",
    "# Load reference sizes\n",
    "s = open(\"sizes.txt\", \"rb\")\n",
    "sizes = pickle.load(s)\n",
    "\n",
    "# Plot all F1-score vs. data samples (8 subplots)\n",
    "print(\"Generating and saving all classification results for this database...\")\n",
    "\n",
    "# fig, ax = plt.subplots(4,2)\n",
    "\n",
    "# # Set IEEE style \n",
    "# plt.style.use(['science','ieee'])\n",
    "\n",
    "# # Iterating the dictionary to plot the CTGAN-based combinations    \n",
    "# for m in range(len(ctgan_combinations)) :  \n",
    "    \n",
    "#     for i in range(len(models)):\n",
    "        \n",
    "#         x_vector = np.zeros(len(sizes_keys)) # Vector to fill before plotting the errorbar\n",
    "#         y_vector = np.zeros(len(sizes_keys))\n",
    "#         err_vector = np.zeros(len(sizes_keys))\n",
    "        \n",
    "#         for method in ctgan_combinations:\n",
    "            \n",
    "#             for j in range(len(sizes_keys)):\n",
    "\n",
    "#                 x_vector[j] = sizes[j]\n",
    "#                 y_vector[j] = class_metrics[models[i]][ctgan_combinations[m]][sizes_keys[j]]['f1'].mean()\n",
    "#                 err_vector[j] = class_metrics[models[i]][ctgan_combinations[m]][sizes_keys[j]]['f1'].std()\n",
    "\n",
    "#         ax[m,0].errorbar(x_vector, y_vector, err_vector, capsize = 4.0, linestyle=':', marker='o', color=model_colors[i])\n",
    "\n",
    "#         # Plot the reference lines (Validation results without synthetic data)\n",
    "#         ax[m,0].axhline(y=SVM_f1_nosynth, color='b', linestyle='--')  \n",
    "#         ax[m,0].axhline(y=rf_f1_nosynth, color='r', linestyle='--') \n",
    "#         ax[m,0].axhline(y=xgb_f1_nosynth, color='k', linestyle='--') \n",
    "#         ax[m,0].axhline(y=knn_f1_nosynth, color='g', linestyle='--') \n",
    "\n",
    "#         # Write the name of the chosen methods\n",
    "#         fig.text(0.15, 0.15 + m*0.2, ctgan_combinations[m])\n",
    "\n",
    "# # Iterating the dictionary to plot the GC-based combinations    \n",
    "# for m in range(len(gc_combinations)) :  \n",
    "    \n",
    "#     for i in range(len(models)):\n",
    "        \n",
    "#         x_vector = np.zeros(len(sizes_keys)) # Vector to fill before plotting the errorbar\n",
    "#         y_vector = np.zeros(len(sizes_keys))\n",
    "#         err_vector = np.zeros(len(sizes_keys))\n",
    "        \n",
    "#         for method in gc_combinations:\n",
    "            \n",
    "#             for j in range(len(sizes_keys)):\n",
    "\n",
    "#                 x_vector[j] = sizes[j]\n",
    "#                 y_vector[j] = class_metrics[models[i]][gc_combinations[m]][sizes_keys[j]]['f1'].mean()\n",
    "#                 err_vector[j] = class_metrics[models[i]][gc_combinations[m]][sizes_keys[j]]['f1'].std()\n",
    "\n",
    "#         ax[m,1].errorbar(x_vector, y_vector, err_vector, capsize = 4.0, linestyle=':', marker='o', color=model_colors[i])\n",
    "\n",
    "#         # Plot the reference lines (Validation results without synthetic data)\n",
    "#         ax[m,1].axhline(y=SVM_f1_nosynth, color='b', linestyle='--')  \n",
    "#         ax[m,1].axhline(y=rf_f1_nosynth, color='r', linestyle='--') \n",
    "#         ax[m,1].axhline(y=xgb_f1_nosynth, color='k', linestyle='--') \n",
    "#         ax[m,1].axhline(y=knn_f1_nosynth, color='g', linestyle='--') \n",
    "\n",
    "#         # Write the name of the chosen methods\n",
    "#         fig.text(0.60, 0.15 + m*0.2, gc_combinations[m])\n",
    "\n",
    "# # Set figure text \n",
    "# fig.text(0.5, 0.04, 'NÂº of samples', ha='center')\n",
    "# fig.text(0.01, 0.5, 'F1-score', va='center', rotation='vertical')\n",
    "\n",
    "# # Remove x-labels\n",
    "# ax[0,0].set_xticklabels([])\n",
    "# ax[1,0].set_xticklabels([])\n",
    "# ax[2,0].set_xticklabels([])\n",
    "# ax[0,1].set_xticklabels([])\n",
    "# ax[1,1].set_xticklabels([])\n",
    "# ax[2,1].set_xticklabels([])\n",
    "\n",
    "# # Set legend \n",
    "# ax[0,0].legend(models, bbox_to_anchor=(0.07,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=4, prop={'size': 6})\n",
    "\n",
    "# name = dataset_name + \"_f1_vs_data_samples_ALL_CASES\"\n",
    "# plt.savefig(name, dpi = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FIGURE I - Scatter plots with trend line: Metrics vs. Data size\n",
    "print(\"Generating and saving Figure 1...\")    \n",
    "\n",
    "# Figure \n",
    "fig, axs = plt.subplots(3,2)\n",
    "    \n",
    "# Set IEEE style \n",
    "plt.style.use(['science','ieee'])\n",
    "\n",
    "# CTGAN Plotting\n",
    "for i in range(len(ctgan_combinations)):\n",
    "\n",
    "   temp_pcd  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "   temp_mmd  = np.zeros(len(sizes_keys))\n",
    "   temp_kld  = np.zeros(len(sizes_keys))\n",
    "\n",
    "   for j in range(len(sizes_keys)):\n",
    "\n",
    "      k = -1 # counter to -1 one to begin in 0\n",
    "\n",
    "      for metric in mets :\n",
    "\n",
    "         k = k + 1 # counter increments to draw the next cell\n",
    "\n",
    "         scatter1 = axs[k,0].scatter(sizes[j], sdg_metrics[ctgan_combinations[i]][sizes_keys[j]][metric].mean(), color = ctgan_colors[i])\n",
    "    \n",
    "      temp_pcd[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['PCD'].mean()\n",
    "      temp_mmd[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['MMD'].mean()\n",
    "      temp_kld[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "   # Calulate and draw the polynom\n",
    "   z_pcd = np.polyfit(sizes, temp_pcd, 1)\n",
    "   p_pcd = np.poly1d(z_pcd)\n",
    "\n",
    "   z_mmd = np.polyfit(sizes, temp_mmd, 1)\n",
    "   p_mmd = np.poly1d(z_mmd)\n",
    "\n",
    "   z_kld = np.polyfit(sizes, temp_kld, 1)\n",
    "   p_kld = np.poly1d(z_kld)\n",
    "\n",
    "   # Line format must be specified different with orange colour\n",
    "   line = ctgan_colors[i]+\"--\"\n",
    "   axs[0,0].plot(sizes,p_pcd(sizes), line)\n",
    "   axs[1,0].plot(sizes,p_mmd(sizes), line)\n",
    "   axs[2,0].plot(sizes,p_kld(sizes), line)\n",
    "\n",
    "# Gaussian Copula Plotting\n",
    "for i in range(len(gc_combinations)):\n",
    "\n",
    "   temp_pcd  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "   temp_mmd  = np.zeros(len(sizes_keys))\n",
    "   temp_kld  = np.zeros(len(sizes_keys))\n",
    "\n",
    "   for j in range(len(sizes_keys)):\n",
    "\n",
    "      k = -1 # counter to -1 one to begin in 0\n",
    "\n",
    "      for metric in mets :\n",
    "\n",
    "         k = k + 1 # counter increments to draw the next cell\n",
    "\n",
    "         scatter2 = axs[k,1].scatter(sizes[j], sdg_metrics[gc_combinations[i]][sizes_keys[j]][metric].mean(), color = gc_colors[i])\n",
    "    \n",
    "      temp_pcd[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['PCD'].mean()\n",
    "      temp_mmd[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['MMD'].mean()\n",
    "      temp_kld[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "   # Calulate and draw the polynom\n",
    "   z_pcd = np.polyfit(sizes, temp_pcd, 1)\n",
    "   p_pcd = np.poly1d(z_pcd)\n",
    "\n",
    "   z_mmd = np.polyfit(sizes, temp_mmd, 1)\n",
    "   p_mmd = np.poly1d(z_mmd)\n",
    "\n",
    "   z_kld = np.polyfit(sizes, temp_kld, 1)\n",
    "   p_kld = np.poly1d(z_kld)\n",
    "\n",
    "   # Line format must be specified different with orange colour\n",
    "   axs[0,1].plot(sizes,p_pcd(sizes), c = gc_colors[i], ls = \"--\")\n",
    "   axs[1,1].plot(sizes,p_mmd(sizes), c = gc_colors[i], ls = \"--\")\n",
    "   axs[2,1].plot(sizes,p_kld(sizes), c = gc_colors[i], ls = \"--\")\n",
    "\n",
    "# Remove x-labels\n",
    "axs[0,0].set_xticklabels([])\n",
    "axs[1,0].set_xticklabels([])\n",
    "axs[0,1].set_xticklabels([])\n",
    "axs[1,1].set_xticklabels([])\n",
    "\n",
    "# Set figure text\n",
    "fig.text(0.5, 0.04, 'NÂº of samples', ha='center')\n",
    "fig.text(0.02, 0.75, 'PCD', va='center', rotation='vertical')\n",
    "fig.text(0.02, 0.5, 'MMD', va='center', rotation='vertical')\n",
    "fig.text(0.02, 0.25, 'KLD', va='center', rotation='vertical')\n",
    "\n",
    "axs[1,0].tick_params(axis='y', labelsize=5, pad = 0.1)\n",
    "axs[1,1].tick_params(axis='y', labelsize=5, pad = 0.1)\n",
    "\n",
    "# Set legend\n",
    "# axs[0,0].legend(ctgan_combinations, bbox_to_anchor=(-0.25,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=2, prop={'size': 4})\n",
    "# axs[0,1].legend(gc_combinations, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=2, prop={'size': 4})\n",
    "\n",
    "name = dataset_name + \"_metrics_vs_synthetic_data_samples.png\"\n",
    "# plt.show()\n",
    "plt.savefig(name, dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # FIGURE II - F1-Score versus data samples (Best abd worst cases) \n",
    "# print(\"Generating and saving Figure 2...\") \n",
    "\n",
    "# fig, ax = plt.subplots(2)\n",
    "\n",
    "# # Set IEEE style \n",
    "# plt.style.use(['science','ieee'])\n",
    "\n",
    "# # Iterating the dictionary to plot the correspondant contents   \n",
    "# for m in range(len(best_worst)) :  \n",
    "    \n",
    "#     for i in range(len(models)):\n",
    "        \n",
    "#         x_vector = np.zeros(len(sizes_keys)) # Vector to fill before plotting the errorbar\n",
    "#         y_vector = np.zeros(len(sizes_keys))\n",
    "#         err_vector = np.zeros(len(sizes_keys))\n",
    "        \n",
    "#         for method in best_worst:\n",
    "            \n",
    "#             for j in range(len(sizes_keys)):\n",
    "\n",
    "#                 x_vector[j] = sizes[j]\n",
    "#                 y_vector[j] = class_metrics[models[i]][best_worst[m]][sizes_keys[j]]['f1'].mean()\n",
    "#                 err_vector[j] = class_metrics[models[i]][best_worst[m]][sizes_keys[j]]['f1'].std()\n",
    "\n",
    "#         ax[m].errorbar(x_vector, y_vector, err_vector, capsize = 4.0, linestyle=':', marker='o', color=model_colors[i])\n",
    "\n",
    "# # Set figure text \n",
    "# fig.text(0.5, 0.04, 'NÂº of samples', ha='center')\n",
    "# fig.text(0.01, 0.5, 'F1-score', va='center', rotation='vertical')\n",
    "\n",
    "# # Write the name of the chosen methods\n",
    "# fig.text(0.20, 0.15, best_worst[0])\n",
    "# fig.text(0.20, 0.55, best_worst[1])\n",
    "\n",
    "# # Remove x-labels\n",
    "# ax[0].set_xticklabels([])\n",
    "\n",
    "# # Set legend \n",
    "# ax[0].legend(models, bbox_to_anchor=(0.07,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=4, prop={'size': 6})\n",
    "\n",
    "# # Plot the reference lines (Validation results without synthetic data)\n",
    "# ax[0].axhline(y=SVM_f1_nosynth, color='b', linestyle='--')  \n",
    "# ax[0].axhline(y=rf_f1_nosynth, color='r', linestyle='--') \n",
    "# ax[0].axhline(y=xgb_f1_nosynth, color='k', linestyle='--') \n",
    "# ax[0].axhline(y=knn_f1_nosynth, color='g', linestyle='--')  \n",
    "# ax[1].axhline(y=SVM_f1_nosynth, color='b', linestyle='--')  \n",
    "# ax[1].axhline(y=rf_f1_nosynth, color='r', linestyle='--') \n",
    "# ax[1].axhline(y=xgb_f1_nosynth, color='k', linestyle='--') \n",
    "# ax[1].axhline(y=knn_f1_nosynth, color='g', linestyle='--')              \n",
    "\n",
    "# name = dataset_name + \"_f1_vs_data_samples\"\n",
    "# plt.savefig(name, dpi = 600)\n",
    "\n",
    "# # FIGURE III: Metrics vs. F1-Score\n",
    "# print(\"Generating and saving Figure 3...\") \n",
    "\n",
    "# # Best combination: ADASYN + GC\n",
    "# best_method = \"NC + GC\"\n",
    "\n",
    "# fig, ax = plt.subplots(3)\n",
    "\n",
    "# plt.style.use(['science','ieee'])\n",
    "\n",
    "# for i in range(len(models)): \n",
    "\n",
    "#     temp_f1  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "#     temp_pcd  = np.zeros(len(sizes_keys)) \n",
    "#     temp_mmd  = np.zeros(len(sizes_keys)) \n",
    "#     temp_kld  = np.zeros(len(sizes_keys)) \n",
    "\n",
    "#     for j in range(len(sizes_keys)): \n",
    "        \n",
    "#         for k in range(len(mets)):\n",
    "            \n",
    "#             scatter1 = ax[k].scatter(class_metrics[models[i]][best_method][sizes_keys[j]]['f1'].mean(), \n",
    "#                         sdg_metrics[best_method][sizes_keys[j]][mets[k]].mean(),\n",
    "#                         color = model_colors[i])            \n",
    "    \n",
    "#         temp_f1[j] = class_metrics[models[i]][best_method][sizes_keys[j]]['f1'].mean()\n",
    "#         temp_pcd[j] = sdg_metrics[best_method][sizes_keys[j]]['PCD'].mean()\n",
    "#         temp_mmd[j] = sdg_metrics[best_method][sizes_keys[j]]['MMD'].mean()\n",
    "#         temp_kld[j] = sdg_metrics[best_method][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "#     line = model_colors[i]+\"--\"\n",
    "\n",
    "#     z_pcd = np.polyfit(temp_f1, temp_pcd, 1)\n",
    "#     p_pcd = np.poly1d(z_pcd)\n",
    "#     ax[0].plot(temp_f1,p_pcd(temp_f1), line)\n",
    "\n",
    "#     z_mmd = np.polyfit(temp_f1, temp_mmd, 1)\n",
    "#     p_mmd = np.poly1d(z_mmd)\n",
    "#     ax[1].plot(temp_f1,p_mmd(temp_f1), line)\n",
    "\n",
    "#     z_kld = np.polyfit(temp_f1, temp_kld, 1)\n",
    "#     p_kld = np.poly1d(z_kld)\n",
    "#     ax[2].plot(temp_f1,p_kld(temp_f1), line)\n",
    "\n",
    "# # Set figure text \n",
    "# fig.text(0.5, 0.04, 'F1-Score', ha='center')\n",
    "# fig.text(0.01, 0.75, 'PCD', va='center', rotation='vertical')\n",
    "# fig.text(0.01, 0.5, 'MMD', va='center', rotation='vertical')\n",
    "# fig.text(0.01, 0.25, 'KLD', va='center', rotation='vertical')\n",
    "\n",
    "# # Remove x-labels\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[1].set_xticklabels([])\n",
    "\n",
    "# # Set legend \n",
    "# ax[0].legend(models, bbox_to_anchor=(0.07,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=4, prop={'size': 6})\n",
    "# # Save figure\n",
    "# name = dataset_name + \"_sdg_metrics_vs_f1_score\"\n",
    "# plt.savefig(name, dpi=600)\n",
    "\n",
    "# Print the best upgrade and worst downgrade, the correspondant method and the percentage of used synthetic data \n",
    "all_combs = [comb1, comb2, comb3, comb4, comb5, comb6, comb7, comb8]\n",
    "\n",
    "finals_f1 = list()\n",
    "\n",
    "for model in models: \n",
    "    for comb in all_combs:\n",
    "        \n",
    "        a = list()\n",
    "\n",
    "        for size in sizes_keys:   \n",
    "            finals_f1.append([class_metrics[model][comb][size]['f1'].mean(), model, comb, size])\n",
    "\n",
    "# Split lists into sublist of the different ML classifiers used \n",
    "svm_finals_f1 = list()\n",
    "for idx in range(len(finals_f1)): \n",
    "    if 'SVM' in finals_f1[idx]: \n",
    "        svm_finals_f1.append(finals_f1[idx]) \n",
    "\n",
    "rf_finals_f1 = list()\n",
    "for idx in range(len(finals_f1)): \n",
    "    if 'RF' in finals_f1[idx]: \n",
    "        rf_finals_f1.append(finals_f1[idx]) \n",
    "\n",
    "xgb_finals_f1 = list()\n",
    "for idx in range(len(finals_f1)): \n",
    "    if 'XGB' in finals_f1[idx]: \n",
    "        xgb_finals_f1.append(finals_f1[idx]) \n",
    "\n",
    "knn_finals_f1 = list()\n",
    "for idx in range(len(finals_f1)): \n",
    "    if 'KNN' in finals_f1[idx]: \n",
    "        knn_finals_f1.append(finals_f1[idx]) \n",
    "\n",
    "\n",
    "print(\"\\nMaximum upgrade in F1-Score using SVM is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((max(svm_finals_f1)[0] - SVM_f1_nosynth), max(svm_finals_f1)[2], max(svm_finals_f1)[3]))\n",
    "print(\"Maximum upgrade in F1-Score using RF is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((max(rf_finals_f1)[0] - rf_f1_nosynth), max(rf_finals_f1)[2], max(rf_finals_f1)[3]))\n",
    "print(\"Maximum upgrade in F1-Score using XGB is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((max(xgb_finals_f1)[0] - xgb_f1_nosynth), max(xgb_finals_f1)[2], max(xgb_finals_f1)[3]))\n",
    "print(\"Maximum upgrade in F1-Score using KNN is: %f, using '%s' SDG technique and '%s' amound of synthetic data\\n\" % ((max(knn_finals_f1)[0] - knn_f1_nosynth), max(knn_finals_f1)[2], max(knn_finals_f1)[3]))\n",
    "\n",
    "print(\"Worst downgrade in F1-Score using SVM is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((min(svm_finals_f1)[0] - SVM_f1_nosynth), min(svm_finals_f1)[2], min(svm_finals_f1)[3]))\n",
    "print(\"Worst downgrade in F1-Score using RF is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((min(rf_finals_f1)[0] - rf_f1_nosynth), min(rf_finals_f1)[2], min(rf_finals_f1)[3]))\n",
    "print(\"Worst downgrade in F1-Score using XGB is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((min(xgb_finals_f1)[0] - xgb_f1_nosynth), min(xgb_finals_f1)[2], min(xgb_finals_f1)[3]))\n",
    "print(\"Worst downgrade in F1-Score using KNN is: %f, using '%s' SDG technique and '%s' amount of synthetic data\" % ((min(knn_finals_f1)[0] - knn_f1_nosynth), min(knn_finals_f1)[2], min(knn_finals_f1)[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIGURE III: Metrics vs. F1-Score\n",
    "print(\"Generating and saving Figure 3...\") \n",
    "\n",
    "# Best combination: ADASYN + GC\n",
    "best_method = \"Borderline + GC\"\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "mets = ['KLD']\n",
    "\n",
    "plt.style.use(['science','ieee'])\n",
    "\n",
    "for i in range(len(models)): \n",
    "\n",
    "    temp_f1  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "    temp_pcd  = np.zeros(len(sizes_keys)) \n",
    "    temp_mmd  = np.zeros(len(sizes_keys)) \n",
    "    temp_kld  = np.zeros(len(sizes_keys)) \n",
    "\n",
    "    for j in range(len(sizes_keys)): \n",
    "        \n",
    "        for k in range(len(mets)):\n",
    "            \n",
    "            scatter1 = ax.scatter(class_metrics[models[i]][best_method][sizes_keys[j]]['f1'].mean(), \n",
    "                        sdg_metrics[best_method][sizes_keys[j]][mets[k]].mean(),\n",
    "                        color = model_colors[i])            \n",
    "    \n",
    "        temp_f1[j] = class_metrics[models[i]][best_method][sizes_keys[j]]['f1'].mean()\n",
    "        # temp_pcd[j] = sdg_metrics[best_method][sizes_keys[j]]['PCD'].mean()\n",
    "        # temp_mmd[j] = sdg_metrics[best_method][sizes_keys[j]]['MMD'].mean()\n",
    "        temp_kld[j] = sdg_metrics[best_method][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "    line = model_colors[i]+\"--\"\n",
    "\n",
    "    # z_pcd = np.polyfit(temp_f1, temp_pcd, 1)\n",
    "    # p_pcd = np.poly1d(z_pcd)\n",
    "    # ax.plot(temp_f1,p_pcd(temp_f1), line)\n",
    "\n",
    "    # z_mmd = np.polyfit(temp_f1, temp_mmd, 1)\n",
    "    # p_mmd = np.poly1d(z_mmd)\n",
    "    # ax.plot(temp_f1,p_mmd(temp_f1), line)\n",
    "\n",
    "    z_kld = np.polyfit(temp_f1, temp_kld, 1)\n",
    "    p_kld = np.poly1d(z_kld)\n",
    "    ax.plot(temp_f1,p_kld(temp_f1), line)\n",
    "\n",
    "# Set figure text \n",
    "fig.text(0.5, 0.04, 'F1-Score', ha='center')\n",
    "fig.text(0.01, 0.5, 'KLD', va='center', rotation='vertical')\n",
    "# fig.text(0.01, 0.5, 'MMD', va='center', rotation='vertical')\n",
    "# fig.text(0.01, 0.25, 'KLD', va='center', rotation='vertical')\n",
    "\n",
    "# Remove x-labels\n",
    "#ax[0].set_xticklabels([])\n",
    "#ax[1].set_xticklabels([])\n",
    "\n",
    "# Set legend \n",
    "leg1=ax.legend(models, bbox_to_anchor=(0.07,1.02,1,0.2), loc=\"lower left\",\n",
    "                mode=\"None\", borderaxespad=0, ncol=4, prop={'size': 6})\n",
    "\n",
    "leg1.legendHandles[0].set_color(model_colors[0])\n",
    "leg1.legendHandles[1].set_color(model_colors[1])\n",
    "leg1.legendHandles[2].set_color(model_colors[2])\n",
    "leg1.legendHandles[3].set_color(model_colors[3])\n",
    "\n",
    "# Save figure\n",
    "name = dataset_name + \"_sdg_metrics_vs_f1_score_ONLY_KLD.png\"\n",
    "plt.savefig(name, dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FIGURE I - Scatter plots with trend line: Metrics vs. Data size\n",
    "print(\"Generating and saving Figure 1...\")\n",
    "\n",
    "mets = [\"PCD\",\"MMD\",\"KLD\"]\n",
    "\n",
    "# Figure \n",
    "fig, axs = plt.subplots(3,2)\n",
    "    \n",
    "# Set IEEE style \n",
    "plt.style.use(['science','ieee'])\n",
    "\n",
    "# CTGAN Plotting\n",
    "for i in range(len(ctgan_combinations)):\n",
    "\n",
    "   temp_pcd  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "   temp_mmd  = np.zeros(len(sizes_keys))\n",
    "   temp_kld  = np.zeros(len(sizes_keys))\n",
    "\n",
    "   for j in range(len(sizes_keys)):\n",
    "\n",
    "      k = -1 # counter to -1 one to begin in 0\n",
    "\n",
    "      for metric in mets :\n",
    "\n",
    "         k = k + 1 # counter increments to draw the next cell\n",
    "\n",
    "         scatter1 = axs[k,0].scatter(sizes[j], sdg_metrics[ctgan_combinations[i]][sizes_keys[j]][metric].mean(), color = ctgan_colors[i])\n",
    "    \n",
    "      temp_pcd[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['PCD'].mean()\n",
    "      temp_mmd[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['MMD'].mean()\n",
    "      temp_kld[j] = sdg_metrics[ctgan_combinations[i]][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "   # Calulate and draw the polynom\n",
    "   z_pcd = np.polyfit(sizes, temp_pcd, 1)\n",
    "   p_pcd = np.poly1d(z_pcd)\n",
    "\n",
    "   z_mmd = np.polyfit(sizes, temp_mmd, 1)\n",
    "   p_mmd = np.poly1d(z_mmd)\n",
    "\n",
    "   z_kld = np.polyfit(sizes, temp_kld, 1)\n",
    "   p_kld = np.poly1d(z_kld)\n",
    "\n",
    "   # Line format must be specified different with orange colour\n",
    "   line = ctgan_colors[i]+\"--\"\n",
    "   axs[0,0].plot(sizes,p_pcd(sizes), line)\n",
    "   axs[1,0].plot(sizes,p_mmd(sizes), line)\n",
    "   axs[2,0].plot(sizes,p_kld(sizes), line)\n",
    "\n",
    "# Gaussian Copula Plotting\n",
    "for i in range(len(gc_combinations)):\n",
    "\n",
    "   temp_pcd  = np.zeros(len(sizes_keys)) # variable to generate polyfit\n",
    "   temp_mmd  = np.zeros(len(sizes_keys))\n",
    "   temp_kld  = np.zeros(len(sizes_keys))\n",
    "\n",
    "   for j in range(len(sizes_keys)):\n",
    "\n",
    "      k = -1 # counter to -1 one to begin in 0\n",
    "\n",
    "      for metric in mets :\n",
    "\n",
    "         k = k + 1 # counter increments to draw the next cell\n",
    "\n",
    "         scatter2 = axs[k,1].scatter(sizes[j], sdg_metrics[gc_combinations[i]][sizes_keys[j]][metric].mean(), color = gc_colors[i])\n",
    "    \n",
    "      temp_pcd[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['PCD'].mean()\n",
    "      temp_mmd[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['MMD'].mean()\n",
    "      temp_kld[j] = sdg_metrics[gc_combinations[i]][sizes_keys[j]]['KLD'].mean()\n",
    "    \n",
    "   # Calulate and draw the polynom\n",
    "   z_pcd = np.polyfit(sizes, temp_pcd, 1)\n",
    "   p_pcd = np.poly1d(z_pcd)\n",
    "\n",
    "   z_mmd = np.polyfit(sizes, temp_mmd, 1)\n",
    "   p_mmd = np.poly1d(z_mmd)\n",
    "\n",
    "   z_kld = np.polyfit(sizes, temp_kld, 1)\n",
    "   p_kld = np.poly1d(z_kld)\n",
    "\n",
    "   # Line format must be specified different with orange colour\n",
    "   axs[0,1].plot(sizes,p_pcd(sizes), c = gc_colors[i], ls = \"--\")\n",
    "   axs[1,1].plot(sizes,p_mmd(sizes), c = gc_colors[i], ls = \"--\")\n",
    "   axs[2,1].plot(sizes,p_kld(sizes), c = gc_colors[i], ls = \"--\")\n",
    "\n",
    "# Remove x-labels\n",
    "axs[0,0].set_xticklabels([])\n",
    "axs[1,0].set_xticklabels([])\n",
    "axs[0,1].set_xticklabels([])\n",
    "axs[1,1].set_xticklabels([])\n",
    "\n",
    "# Set figure text\n",
    "fig.text(0.5, 0.04, 'NÂº of samples', ha='center')\n",
    "fig.text(0.02, 0.75, 'PCD', va='center', rotation='vertical')\n",
    "fig.text(0.02, 0.5, 'MMD', va='center', rotation='vertical')\n",
    "fig.text(0.02, 0.25, 'KLD', va='center', rotation='vertical')\n",
    "\n",
    "axs[1,0].tick_params(axis='y', labelsize=5, pad = 0.1)\n",
    "axs[1,1].tick_params(axis='y', labelsize=5, pad = 0.1)\n",
    "\n",
    "# Exponent size\n",
    "t = axs[1,1].yaxis.get_offset_text()\n",
    "t.set_size(4)\n",
    "\n",
    "t = axs[1,0].yaxis.get_offset_text()\n",
    "t.set_size(4)\n",
    "\n",
    "# Set legend\n",
    "# axs[0,0].legend(ctgan_combinations, bbox_to_anchor=(-0.25,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=2, prop={'size': 4})\n",
    "# axs[0,1].legend(gc_combinations, bbox_to_anchor=(0,1.02,1,0.2), loc=\"lower left\",\n",
    "#                 mode=\"None\", borderaxespad=0, ncol=2, prop={'size': 4})\n",
    "\n",
    "name = dataset_name + \"_metrics_vs_synthetic_data_samples.png\"\n",
    "# plt.show()\n",
    "plt.savefig(name, dpi=600)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f77607bdd0689b41f154633b23853ec31fe773c64b2ce3741f2eac487cf945d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('SDG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
